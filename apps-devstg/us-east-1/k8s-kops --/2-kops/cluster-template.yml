# Ref1: https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md
# Ref2: https://github.com/kubernetes/kops/blob/master/docs/manifests_and_customizing_via_api.md
apiVersion: kops/v1alpha2
kind: Cluster
metadata:
  name: {{ .cluster_name.value }}
spec:
  api:
    #
    # When configuring a LoadBalancer, you can also choose to have a public ELB
    # or an internal (VPC only) ELB. The type field should be Public or Internal.
    #
    loadBalancer:
      type: Internal
      class : Network
      additionalSecurityGroups: [ {{ .cluster_api_elb_extra_security_group.value }} ]
  authentication:
    aws:
      backendMode: CRD
      clusterId: {{ .cluster_name.value }}
      identityMappings:
      - arn: {{ .devops_role.value }}
        username: admin:{{"{{"}} SessionName {{"}}"}}
        groups:
        - system:masters
  authorization:
    rbac: {}
  channel: stable
  cloudLabels:
    Environment: {{ .environment.value }}
    Provisioner: kops
    Service: kubernetes
    Backup: "True"
  cloudProvider: aws
  configBase: s3://{{ .kops_s3_bucket.value }}/{{ .cluster_name.value }}
  {{ if not .gossip_cluster }}
  dnsZone: {{ .hosted_zone_id.value }}
  {{ end }}
  #
  # This block contains configurations for kube-dns.
  #
  kubeDNS:
    provider: KubeDNS
  #
  # Define etcd members (as many as masters were defined)
  #
  etcdClusters:
  - etcdMembers:
  {{ range $i, $az := .cluster_master_azs.value }}
    - instanceGroup: master-{{ . }}
      name: {{ . | replace $.region.value "" }}
      encryptedVolume: true
  {{ end }}
    name: main
    version: {{ .etcd_clusters_version.value }}
  - etcdMembers:
  {{ range $i, $az := .cluster_master_azs.value }}
    - instanceGroup: master-{{ . }}
      name: {{ . | replace $.region.value "" }}
      encryptedVolume: true
  {{ end }}
    name: events
    version: {{ .etcd_clusters_version.value }}
  #
  # This array configures the CIDRs that are able to access the kubernetes API.
  # On AWS this is manifested as inbound security group rules on the ELB or
  # master security groups.
  #
  kubernetesApiAccess:
  - {{ .shared_vpc_cidr_block.value }}
  kubernetesVersion: {{ .cluster_version.value }}
  masterInternalName: api.internal.{{ .cluster_name.value }}
  masterPublicName: api.{{ .cluster_name.value }}
  networkCIDR: {{ .vpc_cidr_block.value }}
  networkID: {{ .vpc_id.value }}
  #
  # Ref1: https://github.com/kubernetes/kops/blob/master/docs/networking.md
  #
  networking:
    calico:
      majorVersion: {{ .networking_calico_major_version.value }}
  nonMasqueradeCIDR: 100.64.0.0/10
  #
  # This array configures the CIDRs that are able to ssh into nodes. On AWS this
  # is manifested as inbound security group rules on the nodes and master
  # security groups.
  #
  sshAccess:
  - {{ .shared_vpc_cidr_block.value }}
  subnets:
  #
  # Define all public (utility) subnets that should be available for the cluster
  #
  {{ range $az, $id := .public_subnet_ids.value }}
  - id: {{ $id }}
    name: utility-{{ $az }}
    type: Utility
    zone: {{ $az }}
  {{ end }}
  #
  # Define all private subnets that should be available for the cluster
  #
  {{ range $az, $id := .private_subnet_ids.value }}
  - id: {{ $id }}
    name: {{ $az }}
    type: Private
    zone: {{ $az }}
    egress: {{ index $.nat_gateway_ids.value $az }}
  {{ end }}
  #
  # Cluster Topology
  #
  topology:
    dns:
      type: Private
    masters: private
    nodes: private
  metricsServer:
    enabled: true
    insecure: true
  clusterAutoscaler:
    enabled: true
  {{ if .irsa_enabled.value }}
  serviceAccountIssuerDiscovery:
    discoveryStore: s3://{{ .irsa_bucket_name.value }}
    enableAWSOIDCProvider: true
  {{ end }}
  {{ if .karpenter_enabled.value }}
  karpenter:
    enabled: true
  {{ end }}

  #
  # Access Mgmt
  #
  iam:
    allowContainerRegistry: true
  {{ if .irsa_enabled.value }}
    useServiceAccountExternalPermissions: true
  {{ end }}
  kubelet:
    anonymousAuth: false
---

#
# Create as many master nodes as were defined
#
{{ range .cluster_master_azs.value }}
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ $.cluster_name.value }}
  name: master-{{ . }}
spec:
  image: {{ $.kops_ami_id.value }}
  kubernetesVersion: {{ $.cluster_version.value }}
  machineType: {{ $.kops_master_machine_type.value }}
  maxSize: {{ $.kops_master_machine_max_size.value }}
  minSize: {{ $.kops_master_machine_min_size.value }}
  role: Master
  subnets:
  - {{ . }}
---
  {{ end }}

#
# Instance group (workers) are defined below, starting with a single group
#
apiVersion: kops/v1alpha2
kind: InstanceGroup
metadata:
  labels:
    kops.k8s.io/cluster: {{ .cluster_name.value }}
  name: nodes
spec:
  {{ if .karpenter_enabled.value }}
  manager: Karpenter
  {{ end }}
  {{ if .node_cloud_labels.value }}
  cloudLabels:
    {{ range $name, $value := .node_cloud_labels.value }}
      {{ $name }}: "{{ $value }}"
    {{ end }}
  {{ end }}
  image: {{ $.kops_ami_id.value }}
  kubernetesVersion: {{ .cluster_version.value }}

  machineType: {{ $.kops_worker_machine_type.value }}

  {{ if .karpenter_enabled.value }}
  mixedInstancesPolicy:
    instances:
      {{ range $.kops_worker_machine_types_karpenter.value }}
        - {{ . }}
      {{ end }}
    #onDemandAboveBase: 5
    #spotAllocationStrategy: price-capacity-optimized
  {{ end }}

  maxSize: {{ $.kops_worker_machine_max_size.value }}
  minSize: {{ $.kops_worker_machine_min_size.value }}
  role: Node
  subnets:
  {{ range .availability_zones.value }}
  - {{ . }}
  {{ end }}

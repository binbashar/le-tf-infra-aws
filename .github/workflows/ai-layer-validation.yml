name: AI-Powered Infrastructure Validation

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'apps-devstg/us-east-1/secrets-manager/**/*.tf'
      - 'apps-devstg/us-east-1/secrets-manager/**/*.tfvars'
      - 'apps-devstg/us-east-1/secrets-manager/**/*.hcl'
  issue_comment:
    types: [created]

permissions:
  contents: read       # Required to read repository contents
  pull-requests: write # Required to post PR comments
  issues: write        # Required for @aibot interactions
  models: read         # Required for GitHub Models API

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  AWS_REGION: us-east-1

jobs:
  # Job 1: Detect affected layers from changed files
  detect-layers:
    name: Detect Modified Layers
    runs-on: ubuntu-latest
    outputs:
      layers: ${{ steps.parse-layers.outputs.layers }}
      has-changes: ${{ steps.parse-layers.outputs.has-changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed files and extract layers
        id: parse-layers
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "🔍 Analyzing changed files in PR #${{ github.event.pull_request.number }}"

          # Get list of changed files from PR
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/files \
            --jq '.[] | select(.status != "removed") | .filename' > changed_files.txt

          echo "📁 Changed files:"
          cat changed_files.txt

          # Force only secrets-manager layer for targeted testing
          echo "🎯 Forcing specific layer for targeted validation: secrets-manager"
          echo "apps-devstg/us-east-1/secrets-manager" > detected_layers.txt

          # Backup: Extract unique layers from changed infrastructure files (disabled)
          # grep -E '\.(tf|tfvars|hcl)$' changed_files.txt | \
          # while IFS='/' read -r account region layer sublayer rest; do
          #   # Handle both 3-level and 4-level layer structures
          #   if [[ -n "$account" && -n "$region" && -n "$layer" ]]; then
          #     if [[ -n "$sublayer" && -d "$account/$region/$layer/$sublayer" ]]; then
          #       # 4-level structure: account/region/layer/sublayer
          #       echo "$account/$region/$layer/$sublayer"
          #     elif [[ -d "$account/$region/$layer" ]]; then
          #       # 3-level structure: account/region/layer
          #       echo "$account/$region/$layer"
          #     fi
          #   fi
          # done | sort -u > detected_layers.txt

          echo "🎯 Detected layers:"
          cat detected_layers.txt

          # Check if we have any valid layers
          if [[ -s detected_layers.txt ]]; then
            # Convert to JSON array for matrix strategy
            layers_json=$(jq -R -s -c 'split("\n") | map(select(length > 0))' detected_layers.txt)
            echo "layers=${layers_json}" >> $GITHUB_OUTPUT
            echo "has-changes=true" >> $GITHUB_OUTPUT
            echo "✅ Found $(wc -l < detected_layers.txt) layer(s) to validate"
          else
            echo "layers=[]" >> $GITHUB_OUTPUT
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "ℹ️ No valid infrastructure layers detected in changes"
          fi

  # Job 2: Validate each layer using Leverage CLI (runs in parallel)
  validate-layers:
    name: Validate Layer
    needs: detect-layers
    if: needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        layer: ${{ fromJson(needs.detect-layers.outputs.layers) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'
          cache: 'pip'

      - name: Setup Python virtual environment and Install Leverage CLI
        run: |
          echo "🐍 Creating Python virtual environment (mirroring local setup)"
          python3 -m venv ~/.leverage-venv
          source ~/.leverage-venv/bin/activate

          echo "📦 Installing latest Leverage CLI in virtual environment"
          pip install --upgrade pip
          pip install leverage

          echo "🔧 Configuring environment for subsequent steps"
          echo "VIRTUAL_ENV=$HOME/.leverage-venv" >> $GITHUB_ENV
          echo "$HOME/.leverage-venv/bin" >> $GITHUB_PATH

          echo "✅ Leverage CLI installed in virtual environment"
          leverage --version


      - name: Configure AWS credentials for Leverage CLI containers
        id: aws-config
        run: |
          # Parse layer information to determine AWS account
          LAYER_PATH="${{ matrix.layer }}"
          ACCOUNT=$(echo "$LAYER_PATH" | cut -d'/' -f1)

          echo "🔑 Configuring AWS credentials for Leverage CLI containers - Account: $ACCOUNT"

          # Simple environment variable setup for Leverage CLI containers
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_DEFAULT_REGION=${{ env.AWS_REGION }}" >> $GITHUB_ENV
          echo "AWS_REGION=${{ env.AWS_REGION }}" >> $GITHUB_ENV

          # Output account for reference (optional)
          echo "account=$ACCOUNT" >> $GITHUB_OUTPUT

          echo "✅ AWS credentials configured for Leverage CLI containers"

      - name: Parse layer information
        id: layer-info
        run: |
          # Extract layer components
          LAYER_PATH="${{ matrix.layer }}"
          ACCOUNT=$(echo "$LAYER_PATH" | cut -d'/' -f1)
          REGION=$(echo "$LAYER_PATH" | cut -d'/' -f2)
          LAYER_NAME=$(echo "$LAYER_PATH" | cut -d'/' -f3)
          SUBLAYER=$(echo "$LAYER_PATH" | cut -d'/' -f4)

          # For 4-level paths, use sublayer for persona selection
          if [[ -n "$SUBLAYER" ]]; then
            LAYER_FOR_PERSONA="$SUBLAYER"
          else
            LAYER_FOR_PERSONA="$LAYER_NAME"
          fi

          # Determine layer type for persona selection
          case "$LAYER_FOR_PERSONA" in
            security-*|secrets-manager|secrets|base-identities) LAYER_TYPE="security" ;;
            base-network|*-vpn|network-*) LAYER_TYPE="network" ;;
            databases-*) LAYER_TYPE="database" ;;
            k8s-*|*-ecs) LAYER_TYPE="container" ;;
            tools-*|*-jenkins|*-monitoring) LAYER_TYPE="devops" ;;
            *-s3|*-backup|*-storage) LAYER_TYPE="storage" ;;
            *-ec2|*-lambda|*-autoscaling) LAYER_TYPE="compute" ;;
            data-*|*-ml|*-bedrock) LAYER_TYPE="data-analytics" ;;
            *) LAYER_TYPE="infrastructure" ;;
          esac

          echo "account=$ACCOUNT" >> $GITHUB_OUTPUT
          echo "region=$REGION" >> $GITHUB_OUTPUT
          echo "layer-name=$LAYER_NAME" >> $GITHUB_OUTPUT
          echo "layer-type=$LAYER_TYPE" >> $GITHUB_OUTPUT

          echo "🏗️ Validating layer: $LAYER_PATH (type: $LAYER_TYPE)"

      - name: Detect Terraform compatibility
        id: tf-compat
        working-directory: ${{ matrix.layer }}
        run: |
          echo "🔍 Detecting Terraform/OpenTofu compatibility..."

          # Default to OpenTofu for modern layers
          TF_COMMAND="tf"
          TF_BINARY="OpenTofu"

          # Check if config.tf exists and analyze version constraints
          if [[ -f "config.tf" ]]; then
            echo "📄 Found config.tf, analyzing version constraints..."

            # Check Terraform required version
            if grep -q "required_version.*~>.*1\.[0-5]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "🔧 Detected legacy Terraform version constraint"
            elif grep -q "required_version.*~>.*1\.[0-3]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "🔧 Detected very old Terraform version constraint"
            fi

            # Check AWS provider version (additional indicator)
            if grep -q "aws.*~>.*[0-4]\\.[0-9]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "🔧 Detected legacy AWS provider version"
            fi
          elif [[ -f "versions.tf" ]]; then
            echo "📄 Found versions.tf, analyzing version constraints..."

            # Check versions.tf for same patterns
            if grep -q "required_version.*~>.*1\.[0-5]" versions.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "🔧 Detected legacy Terraform version in versions.tf"
            fi

            if grep -q "aws.*~>.*[0-4]\\.[0-9]" versions.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "🔧 Detected legacy AWS provider in versions.tf"
            fi
          else
            echo "⚠️ No config.tf or versions.tf found, using default: $TF_BINARY"
          fi

          # Set environment variable for subsequent steps
          echo "TF_COMMAND=$TF_COMMAND" >> $GITHUB_ENV
          echo "tf-command=$TF_COMMAND" >> $GITHUB_OUTPUT
          echo "tf-binary=$TF_BINARY" >> $GITHUB_OUTPUT

          echo "✅ Selected binary: $TF_BINARY (command: leverage $TF_COMMAND)"

      - name: Setup Leverage environment
        id: leverage-setup
        working-directory: ${{ matrix.layer }}
        run: |
          echo "🔧 Setting up Leverage environment..."

          # Navigate to repository root and create minimal build.env
          REPO_ROOT=$(git rev-parse --show-toplevel)
          cd "$REPO_ROOT"

          # Create minimal build.env configuration
          cat > build.env << EOF
          PROJECT=bb
          MFA_ENABLED=false
          TERRAFORM_IMAGE_TAG=1.9.1-tofu-0.3.0
          EOF

          # Source environment for subsequent steps
          source build.env
          echo "PROJECT=$PROJECT" >> $GITHUB_ENV
          echo "MFA_ENABLED=$MFA_ENABLED" >> $GITHUB_ENV
          echo "TERRAFORM_IMAGE_TAG=$TERRAFORM_IMAGE_TAG" >> $GITHUB_ENV

          echo "✅ Leverage environment configured with image: $TERRAFORM_IMAGE_TAG"

      - name: Run Leverage CLI validations
        id: validation
        working-directory: ${{ matrix.layer }}
        run: |
          # Ensure build.env is accessible from current layer directory
          REPO_ROOT=$(git rev-parse --show-toplevel)
          if [[ ! -f "build.env" ]]; then
            ln -s "$REPO_ROOT/build.env" build.env
          fi

          # Initialize validation results
          VALIDATION_RESULTS=""
          VALIDATION_STATUS="success"

          # Function to capture command output with proper error handling
          run_validation() {
            local cmd="$1"
            local description="$2"

            echo "⚡ Running: $description"
            if output=$(timeout 300 $cmd 2>&1); then
              echo "✅ $description: PASSED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n✅ **PASSED**\n\`\`\`\n${output}\n\`\`\`\n\n"
            else
              echo "❌ $description: FAILED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n❌ **FAILED**\n\`\`\`\n${output}\n\`\`\`\n\n"
              VALIDATION_STATUS="failed"
            fi
          }

          echo "🚀 Running Leverage CLI validations in $(pwd)"

          # Configuration paths
          BACKEND_CONFIG="../../config/backend.tfvars"
          ACCOUNT_CONFIG="../../config/account.tfvars"

          # Run format check
          echo "⚡ Running format check..."
          run_validation "leverage tf fmt -check" "Terraform Format Check"

          # Backend initialization with fallback
          echo "⚡ Initializing with backend..."
          if output=$(timeout 300 leverage tf init -no-color -backend-config=$BACKEND_CONFIG 2>&1); then
            echo "✅ Backend initialization successful"
            VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Backend Initialization\n✅ **PASSED**\n\`\`\`\n${output}\n\`\`\`\n\n"
            BACKEND_AVAILABLE=true
          else
            echo "⚠️ Backend init failed, trying syntax-only validation..."
            VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Backend Initialization\n⚠️ **FAILED (trying syntax-only validation)**\n\`\`\`\n${output}\n\`\`\`\n\n"

            if fallback_output=$(timeout 300 leverage tf init -no-color -backend=false 2>&1); then
              echo "✅ Syntax-only initialization successful"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Syntax Initialization\n✅ **PASSED**\n\`\`\`\n${fallback_output}\n\`\`\`\n\n"
              BACKEND_AVAILABLE=false
            else
              echo "❌ Syntax-only initialization failed"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Syntax Initialization\n❌ **FAILED**\n\`\`\`\n${fallback_output}\n\`\`\`\n\n"
              VALIDATION_STATUS="failed"
              BACKEND_AVAILABLE=false
            fi
          fi

          # Run validation
          echo "⚡ Running validation..."
          run_validation "leverage tf validate" "Terraform Validation"

          # Generate plan if backend available
          if [[ "$BACKEND_AVAILABLE" == "true" ]]; then
            echo "⚡ Generating execution plan..."
            run_validation "leverage tf plan -no-color -var-file=$ACCOUNT_CONFIG" "Terraform Plan Generation"
          else
            echo "⚠️ Skipping plan generation (backend not available)"
            VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Plan\n⚠️ **SKIPPED - Missing Dependencies**\n\`\`\`\nBackend initialization failed due to missing remote state dependencies.\nThis is expected for layers that depend on other layers being deployed first.\nSyntax validation was performed successfully.\n\`\`\`\n\n"
          fi

          # Save results for AI analysis
          mkdir -p /tmp/validation-results
          LAYER_FILE_NAME="${{ matrix.layer }}"
          LAYER_FILE_NAME="${LAYER_FILE_NAME//\//-}"  # Replace slashes with dashes
          echo -e "$VALIDATION_RESULTS" > "/tmp/validation-results/${LAYER_FILE_NAME}.md"
          echo "$VALIDATION_STATUS" > "/tmp/validation-results/${LAYER_FILE_NAME}.status"

          echo "status=$VALIDATION_STATUS" >> $GITHUB_OUTPUT

          # Create layer slug for unique artifact naming
          LAYER_SLUG="${{ matrix.layer }}"
          LAYER_SLUG="${LAYER_SLUG//\//-}"  # Replace slashes with dashes
          echo "layer-slug=$LAYER_SLUG" >> $GITHUB_OUTPUT

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        with:
          name: validation-results-${{ steps.validation.outputs.layer-slug }}
          path: /tmp/validation-results/
          retention-days: 1

  # Job 3: AI-powered analysis of validation results
  ai-analysis:
    name: AI Analysis
    needs: [detect-layers, validate-layers]
    if: needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download validation results
        uses: actions/download-artifact@v4
        with:
          pattern: validation-results-*
          path: /tmp/validation-results/
          merge-multiple: true

      - name: Load AI personas configuration
        id: load-personas
        run: |
          # Load AI personas from configuration file
          if [[ -f .github/ai-personas.yml ]]; then
            echo "📚 Loading AI personas configuration"
            cat .github/ai-personas.yml
          else
            echo "⚠️ AI personas configuration not found, using defaults"
          fi

      - name: Analyze validation results with AI
        id: ai-analysis
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "🤖 Starting AI analysis of validation results"

          # Get PR diff for context
          PR_DIFF=$(gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/files \
            --jq '.[] | "File: \(.filename)\nStatus: \(.status)\nChanges: +\(.additions) -\(.deletions)\n---"' | head -c 8000)

          # Collect all validation results
          COMBINED_RESULTS="# Validation Results Summary\n\n"
          OVERALL_STATUS="success"

          for result_file in /tmp/validation-results/*.md; do
            if [[ -f "$result_file" ]]; then
              layer_path=$(basename "$result_file" .md)
              status=$(cat "/tmp/validation-results/${layer_path}.status" 2>/dev/null || echo "unknown")

              if [[ "$status" == "failed" ]]; then
                OVERALL_STATUS="failed"
              fi

              COMBINED_RESULTS="${COMBINED_RESULTS}## Layer: $layer_path (Status: $status)\n"
              COMBINED_RESULTS="${COMBINED_RESULTS}$(cat "$result_file")\n"
            fi
          done

          # Prepare AI prompt (simple format to avoid YAML issues)
          AI_PROMPT_BASE="You are an expert DevOps engineer analyzing Terraform infrastructure changes in a Binbash Leverage Reference Architecture project. Context: Repository ${{ github.repository }}, PR #${{ github.event.pull_request.number }}: ${{ github.event.pull_request.title }}. Architecture: Multi-account AWS with layer-based structure. Please provide: 1. Executive Summary, 2. Key Findings, 3. Potential Issues, 4. Recommendations, 5. Cross-Layer Impact Analysis, 6. Risk Assessment. Focus on infrastructure best practices, security implications, and cross-layer dependencies."

          # Combine prompt with data (truncate if too long)
          FULL_PROMPT="${AI_PROMPT_BASE} PR Changes: $(echo "$PR_DIFF" | head -c 3000) Validation Results: $(echo "$COMBINED_RESULTS" | head -c 3000)"

          # Call GitHub Models API
          echo "🧠 Calling GitHub Models API for analysis..."

          # Create JSON payload and call API
          JSON_PAYLOAD=$(jq -n --arg model "openai/gpt-4.1" --arg content "$FULL_PROMPT" '{"model": $model, "messages": [{"role": "user", "content": $content}], "temperature": 0.3, "max_tokens": 2000}')

          # Make API call with error handling
          echo "Calling GitHub Models API..."
          API_RESPONSE=$(curl -s -w "HTTP_CODE:%{http_code}" -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            -H "Content-Type: application/json" \
            -d "$JSON_PAYLOAD" \
            "https://models.github.ai/inference/chat/completions")

          # Extract HTTP code and response body
          HTTP_CODE=$(echo "$API_RESPONSE" | grep -o 'HTTP_CODE:[0-9]*' | cut -d: -f2)
          RESPONSE_BODY=$(echo "$API_RESPONSE" | sed 's/HTTP_CODE:[0-9]*$//')

          # Process API response
          if [[ "$HTTP_CODE" == "200" ]]; then
            AI_CONTENT=$(echo "$RESPONSE_BODY" | jq -r '.choices[0].message.content // "AI analysis parsing failed"')
            echo "✅ AI analysis successful"
          else
            echo "⚠️ AI analysis failed with HTTP code $HTTP_CODE"
            echo "📋 API Response Body: $RESPONSE_BODY"
            echo "📊 Payload Size: $(echo "$JSON_PAYLOAD" | wc -c) characters"

            # Try to extract error message from response
            ERROR_MSG=$(echo "$RESPONSE_BODY" | jq -r '.error.message // .message // "Unknown error"' 2>/dev/null || echo "Unable to parse error")
            AI_CONTENT="AI analysis temporarily unavailable (HTTP $HTTP_CODE: $ERROR_MSG). Validation results are still available above."
          fi

          # Save AI response
          mkdir -p /tmp/ai-analysis
          echo "$AI_CONTENT" > /tmp/ai-analysis/response.md
          echo "$OVERALL_STATUS" > /tmp/ai-analysis/status.txt

          echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT

      - name: Upload AI analysis
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis
          path: /tmp/ai-analysis/
          retention-days: 1

  # Job 4: Post results as PR comments
  post-results:
    name: Post AI Analysis Results
    needs: [detect-layers, validate-layers, ai-analysis]
    if: always() && needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Download AI analysis
        uses: actions/download-artifact@v4
        with:
          name: ai-analysis
          path: /tmp/ai-analysis/

      - name: Post AI analysis as PR comment
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "💬 Posting AI analysis to PR #${{ github.event.pull_request.number }}"

          # Load AI response
          if [[ -f /tmp/ai-analysis/response.md ]]; then
            AI_RESPONSE=$(cat /tmp/ai-analysis/response.md)
            OVERALL_STATUS=$(cat /tmp/ai-analysis/status.txt)
          else
            AI_RESPONSE="AI analysis was not available for this validation run."
            OVERALL_STATUS="unknown"
          fi

          # Determine status emoji
          case "$OVERALL_STATUS" in
            "success") STATUS_EMOJI="✅" ;;
            "failed") STATUS_EMOJI="❌" ;;
            *) STATUS_EMOJI="⚠️" ;;
          esac

          # Create simple PR comment (building it step by step to avoid YAML issues)
          PR_COMMENT="${STATUS_EMOJI} AI-Powered Infrastructure Validation"
          PR_COMMENT+="\n\n**Overall Status:** \`$OVERALL_STATUS\`"
          PR_COMMENT+="\n\n$AI_RESPONSE"
          PR_COMMENT+="\n\n---"
          PR_COMMENT+="\n**Interactive Commands:** Reply with @aibot commands for additional analysis:"
          PR_COMMENT+="\n- \`@aibot explain security risks\`"
          PR_COMMENT+="\n- \`@aibot blast radius\`"
          PR_COMMENT+="\n- \`@aibot best practices\`"
          PR_COMMENT+="\n\n*Powered by Binbash Leverage + GitHub Models API*"

          # Post comment
          gh api repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/comments \
            --method POST \
            --field body="$PR_COMMENT"

          echo "✅ AI analysis posted successfully"

  # Job 5: Handle @aibot interactive commands (triggered by issue comments)
  handle-aibot:
    name: Handle @aibot Commands
    runs-on: ubuntu-latest
    if: github.event_name == 'issue_comment' && contains(github.event.comment.body, '@aibot')
    steps:
      - name: Process @aibot command
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          COMMENT_BODY="${{ github.event.comment.body }}"
          echo "🤖 Processing @aibot command: $COMMENT_BODY"

          # Extract command after @aibot
          COMMAND=$(echo "$COMMENT_BODY" | sed -n 's/.*@aibot \([^[:space:]]*\).*/\1/p')

          case "$COMMAND" in
            "explain"|"security"|"blast"|"best")
              # Create prompt based on command
              case "$COMMAND" in
                "explain"|"security")
                  BOT_PROMPT="You are a security expert. Analyze the infrastructure changes in this PR and explain potential security risks, vulnerabilities, and recommended mitigations. Focus on AWS security best practices."
                  ;;
                "cost")
                  BOT_PROMPT="You are a cost optimization expert. Analyze the infrastructure changes and estimate cost impact, potential savings opportunities, and cost-effective alternatives."
                  ;;
                "blast")
                  BOT_PROMPT="You are an infrastructure expert. Analyze cross-layer dependencies and predict the blast radius of these changes on other infrastructure components."
                  ;;
                "best")
                  BOT_PROMPT="You are an AWS Well-Architected Framework expert. Review these changes against the 5 pillars: Security, Reliability, Performance, Cost Optimization, and Operational Excellence."
                  ;;
              esac

              # Create JSON payload for API call
              JSON_PAYLOAD=$(jq -n \
                --arg model "openai/gpt-4.1" \
                --arg content "$BOT_PROMPT" \
                '{
                  "model": $model,
                  "messages": [
                    {
                      "role": "user",
                      "content": $content
                    }
                  ],
                  "temperature": 0.3,
                  "max_tokens": 1500
                }')

              # Call GitHub Models API
              AI_RESPONSE=$(curl -s -X POST \
                -H "Accept: application/vnd.github+json" \
                -H "Authorization: Bearer $GITHUB_TOKEN" \
                -H "X-GitHub-Api-Version: 2022-11-28" \
                -H "Content-Type: application/json" \
                -d "$JSON_PAYLOAD" \
                "https://models.github.ai/inference/chat/completions" | \
                jq -r '.choices[0].message.content // "Analysis unavailable"')

              # Reply to comment
              AIBOT_RESPONSE="🤖 **@aibot response for \`$COMMAND\`:**\n\n$AI_RESPONSE"
              gh api repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments \
                --method POST \
                --field body="$AIBOT_RESPONSE"
              ;;
            *)
              AIBOT_HELP="🤖 Available @aibot commands:\n- \`@aibot explain security risks\`\n- \`@aibot blast radius\`\n- \`@aibot best practices\`"
              gh api repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments \
                --method POST \
                --field body="$AIBOT_HELP"
              ;;
          esac
name: AI-Powered Infrastructure Validation

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'apps-devstg/us-east-1/secrets-manager/**/*.tf'
      - 'apps-devstg/us-east-1/secrets-manager/**/*.tfvars'
      - 'apps-devstg/us-east-1/secrets-manager/**/*.hcl'
  issue_comment:
    types: [created]

permissions:
  contents: read       # Required to read repository contents
  pull-requests: write # Required to post PR comments
  issues: write        # Required for @aibot interactions
  models: read         # Required for GitHub Models API

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  AWS_REGION: us-east-1

jobs:
  # Job 1: Detect affected layers from changed files
  detect-layers:
    name: Detect Modified Layers
    runs-on: ubuntu-latest
    outputs:
      layers: ${{ steps.parse-layers.outputs.layers }}
      has-changes: ${{ steps.parse-layers.outputs.has-changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed files and extract layers
        id: parse-layers
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üîç Analyzing changed files in PR #${{ github.event.pull_request.number }}"

          # Get list of changed files from PR
          gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/files \
            --jq '.[] | select(.status != "removed") | .filename' > changed_files.txt

          echo "üìÅ Changed files:"
          cat changed_files.txt

          # Force only secrets-manager layer for targeted testing
          echo "üéØ Forcing specific layer for targeted validation: secrets-manager"
          echo "apps-devstg/us-east-1/secrets-manager" > detected_layers.txt

          # Backup: Extract unique layers from changed infrastructure files (disabled)
          # grep -E '\.(tf|tfvars|hcl)$' changed_files.txt | \
          # while IFS='/' read -r account region layer sublayer rest; do
          #   # Handle both 3-level and 4-level layer structures
          #   if [[ -n "$account" && -n "$region" && -n "$layer" ]]; then
          #     if [[ -n "$sublayer" && -d "$account/$region/$layer/$sublayer" ]]; then
          #       # 4-level structure: account/region/layer/sublayer
          #       echo "$account/$region/$layer/$sublayer"
          #     elif [[ -d "$account/$region/$layer" ]]; then
          #       # 3-level structure: account/region/layer
          #       echo "$account/$region/$layer"
          #     fi
          #   fi
          # done | sort -u > detected_layers.txt

          echo "üéØ Detected layers:"
          cat detected_layers.txt

          # Check if we have any valid layers
          if [[ -s detected_layers.txt ]]; then
            # Convert to JSON array for matrix strategy
            layers_json=$(jq -R -s -c 'split("\n") | map(select(length > 0))' detected_layers.txt)
            echo "layers=${layers_json}" >> $GITHUB_OUTPUT
            echo "has-changes=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Found $(wc -l < detected_layers.txt) layer(s) to validate"
          else
            echo "layers=[]" >> $GITHUB_OUTPUT
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è No valid infrastructure layers detected in changes"
          fi

  # Job 2: Validate each layer using Leverage CLI (runs in parallel)
  validate-layers:
    name: Validate Layer
    needs: detect-layers
    if: needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        layer: ${{ fromJson(needs.detect-layers.outputs.layers) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'
          cache: 'pip'

      - name: Install Leverage CLI
        run: |
          echo "üì¶ Installing latest Leverage CLI"
          pip install --upgrade leverage
          leverage --version

      - name: Configure AWS credentials
        id: aws-config
        run: |
          # Parse layer information to determine AWS account
          LAYER_PATH="${{ matrix.layer }}"
          ACCOUNT=$(echo "$LAYER_PATH" | cut -d'/' -f1)

          echo "üîë Configuring AWS credentials for account: $ACCOUNT"

          # Map account directories to credential secrets
          case "$ACCOUNT" in
            "apps-devstg")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_DEVSTG_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "shared")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_SHARED_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "security")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_SECURITY_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "network")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_NETWORK_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "apps-prd")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_PRD_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "data-science")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_DATA_SCIENCE_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            "management")
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=${{ secrets.AWS_ROOT_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "‚ö†Ô∏è Unknown account directory: $ACCOUNT, using default credentials"
              echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
              echo "account-id=unknown" >> $GITHUB_OUTPUT
              ;;
          esac

          # Set AWS region
          echo "AWS_DEFAULT_REGION=${{ env.AWS_REGION }}" >> $GITHUB_ENV
          echo "‚úÖ AWS credentials configured for account: $ACCOUNT"

      - name: Setup AWS CLI profiles
        id: aws-profiles
        run: |
          # Parse layer information to determine profile name
          LAYER_PATH="${{ matrix.layer }}"
          ACCOUNT=$(echo "$LAYER_PATH" | cut -d'/' -f1)

          echo "üîß Setting up AWS CLI profiles for Leverage compatibility..."

          # Create AWS credentials directory
          mkdir -p ~/.aws

          # Determine profile name based on account (matching Leverage conventions)
          case "$ACCOUNT" in
            "apps-devstg")
              PROFILE_NAME="bb-apps-devstg-devops"
              ;;
            "shared")
              PROFILE_NAME="bb-shared-devops"
              ;;
            "security")
              PROFILE_NAME="bb-security-devops"
              ;;
            "network")
              PROFILE_NAME="bb-network-devops"
              ;;
            "apps-prd")
              PROFILE_NAME="bb-apps-prd-devops"
              ;;
            "data-science")
              PROFILE_NAME="bb-data-science-devops"
              ;;
            "management")
              PROFILE_NAME="bb-management-devops"
              ;;
            *)
              PROFILE_NAME="bb-${ACCOUNT}-devops"
              ;;
          esac

          # Create AWS credentials file
          echo "Creating AWS credentials file..."
          echo "[$PROFILE_NAME]" > ~/.aws/credentials
          echo "aws_access_key_id = $AWS_ACCESS_KEY_ID" >> ~/.aws/credentials
          echo "aws_secret_access_key = $AWS_SECRET_ACCESS_KEY" >> ~/.aws/credentials
          echo "region = ${{ env.AWS_REGION }}" >> ~/.aws/credentials

          # Create AWS config file
          echo "Creating AWS config file..."
          echo "[profile $PROFILE_NAME]" > ~/.aws/config
          echo "region = ${{ env.AWS_REGION }}" >> ~/.aws/config
          echo "output = json" >> ~/.aws/config

          # Set AWS profile for Leverage CLI
          echo "AWS_PROFILE=$PROFILE_NAME" >> $GITHUB_ENV
          echo "aws-profile=$PROFILE_NAME" >> $GITHUB_OUTPUT

          echo "‚úÖ AWS CLI profile configured: $PROFILE_NAME"
          echo "üîç Profile verification:"
          aws configure list --profile "$PROFILE_NAME" || echo "Profile setup completed"

      - name: Parse layer information
        id: layer-info
        run: |
          # Extract layer components
          LAYER_PATH="${{ matrix.layer }}"
          ACCOUNT=$(echo "$LAYER_PATH" | cut -d'/' -f1)
          REGION=$(echo "$LAYER_PATH" | cut -d'/' -f2)
          LAYER_NAME=$(echo "$LAYER_PATH" | cut -d'/' -f3)
          SUBLAYER=$(echo "$LAYER_PATH" | cut -d'/' -f4)

          # For 4-level paths, use sublayer for persona selection
          if [[ -n "$SUBLAYER" ]]; then
            LAYER_FOR_PERSONA="$SUBLAYER"
          else
            LAYER_FOR_PERSONA="$LAYER_NAME"
          fi

          # Determine layer type for persona selection
          case "$LAYER_FOR_PERSONA" in
            security-*|secrets-manager|secrets|base-identities) LAYER_TYPE="security" ;;
            base-network|*-vpn|network-*) LAYER_TYPE="network" ;;
            databases-*) LAYER_TYPE="database" ;;
            k8s-*|*-ecs) LAYER_TYPE="container" ;;
            tools-*|*-jenkins|*-monitoring) LAYER_TYPE="devops" ;;
            *-s3|*-backup|*-storage) LAYER_TYPE="storage" ;;
            *-ec2|*-lambda|*-autoscaling) LAYER_TYPE="compute" ;;
            data-*|*-ml|*-bedrock) LAYER_TYPE="data-analytics" ;;
            *) LAYER_TYPE="infrastructure" ;;
          esac

          echo "account=$ACCOUNT" >> $GITHUB_OUTPUT
          echo "region=$REGION" >> $GITHUB_OUTPUT
          echo "layer-name=$LAYER_NAME" >> $GITHUB_OUTPUT
          echo "layer-type=$LAYER_TYPE" >> $GITHUB_OUTPUT

          echo "üèóÔ∏è Validating layer: $LAYER_PATH (type: $LAYER_TYPE)"

      - name: Detect Terraform compatibility
        id: tf-compat
        working-directory: ${{ matrix.layer }}
        run: |
          echo "üîç Detecting Terraform/OpenTofu compatibility..."

          # Default to OpenTofu for modern layers
          TF_COMMAND="tf"
          TF_BINARY="OpenTofu"

          # Check if config.tf exists and analyze version constraints
          if [[ -f "config.tf" ]]; then
            echo "üìÑ Found config.tf, analyzing version constraints..."

            # Check Terraform required version
            if grep -q "required_version.*~>.*1\.[0-5]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "üîß Detected legacy Terraform version constraint"
            elif grep -q "required_version.*~>.*1\.[0-3]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "üîß Detected very old Terraform version constraint"
            fi

            # Check AWS provider version (additional indicator)
            if grep -q "aws.*~>.*[0-4]\\.[0-9]" config.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "üîß Detected legacy AWS provider version"
            fi
          elif [[ -f "versions.tf" ]]; then
            echo "üìÑ Found versions.tf, analyzing version constraints..."

            # Check versions.tf for same patterns
            if grep -q "required_version.*~>.*1\.[0-5]" versions.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "üîß Detected legacy Terraform version in versions.tf"
            fi

            if grep -q "aws.*~>.*[0-4]\\.[0-9]" versions.tf; then
              TF_COMMAND="terraform"
              TF_BINARY="Terraform (legacy)"
              echo "üîß Detected legacy AWS provider in versions.tf"
            fi
          else
            echo "‚ö†Ô∏è No config.tf or versions.tf found, using default: $TF_BINARY"
          fi

          # Set environment variable for subsequent steps
          echo "TF_COMMAND=$TF_COMMAND" >> $GITHUB_ENV
          echo "tf-command=$TF_COMMAND" >> $GITHUB_OUTPUT
          echo "tf-binary=$TF_BINARY" >> $GITHUB_OUTPUT

          echo "‚úÖ Selected binary: $TF_BINARY (command: leverage $TF_COMMAND)"

      - name: Setup Leverage environment
        id: leverage-setup
        working-directory: ${{ matrix.layer }}
        run: |
          echo "üîß Setting up Leverage environment..."

          # Navigate to repository root to find/create build.env
          REPO_ROOT=$(git rev-parse --show-toplevel)
          cd "$REPO_ROOT"

          # Ensure build.env exists with proper configuration
          if [[ ! -f "build.env" ]]; then
            echo "üìù Creating build.env file..."
            echo "# Project settings" > build.env
            echo "PROJECT=bb" >> build.env
            echo "" >> build.env
            echo "# General" >> build.env
            echo "MFA_ENABLED=false" >> build.env
            echo "" >> build.env
            echo "# Terraform" >> build.env
            echo "TERRAFORM_IMAGE_TAG=1.9.1-tofu-0.3.0" >> build.env
          else
            echo "‚úÖ Found existing build.env file"
          fi

          # Determine appropriate Docker image based on binary selection with fallbacks
          if [[ "${{ steps.tf-compat.outputs.tf-command }}" == "terraform" ]]; then
            # Legacy layers - use pure Terraform image with fallbacks
            DOCKER_IMAGE_CANDIDATES=("1.6.6-latest" "1.5.7-latest" "1.3.5-latest")
            DOCKER_IMAGE_TAG="1.6.6-latest"  # Default for legacy
            echo "üê≥ Using legacy Terraform Docker image: $DOCKER_IMAGE_TAG"
          else
            # Modern layers - use verified OpenTofu images (fallback to original build.env image)
            DOCKER_IMAGE_CANDIDATES=("1.9.1-tofu-0.3.0" "1.6.6-latest" "1.5.7-latest")
            DOCKER_IMAGE_TAG="1.9.1-tofu-0.3.0"  # Original build.env OpenTofu version
            echo "üöÄ Using modern OpenTofu Docker image: $DOCKER_IMAGE_TAG"
          fi

          # Export fallback candidates for the pre-pull step
          echo "DOCKER_IMAGE_CANDIDATES=${DOCKER_IMAGE_CANDIDATES[*]}" >> $GITHUB_ENV

          # Update TERRAFORM_IMAGE_TAG in build.env
          sed -i "s/TERRAFORM_IMAGE_TAG=.*/TERRAFORM_IMAGE_TAG=$DOCKER_IMAGE_TAG/" build.env

          # Source the environment for subsequent steps
          source build.env
          echo "PROJECT=$PROJECT" >> $GITHUB_ENV
          echo "MFA_ENABLED=$MFA_ENABLED" >> $GITHUB_ENV
          echo "TERRAFORM_IMAGE_TAG=$TERRAFORM_IMAGE_TAG" >> $GITHUB_ENV

          echo "‚úÖ Leverage environment configured with image: $TERRAFORM_IMAGE_TAG"

      - name: Pre-pull Docker image
        id: docker-pull
        run: |
          echo "üê≥ Pre-pulling Leverage toolbox Docker image..."
          echo "Image: binbash/leverage-toolbox:$TERRAFORM_IMAGE_TAG"

          # Try primary image first, then fallbacks
          SUCCESSFUL_IMAGE=""

          # Convert space-separated string back to array
          IFS=' ' read -ra CANDIDATES <<< "$DOCKER_IMAGE_CANDIDATES"

          echo "üîÑ Available fallback images: ${CANDIDATES[*]}"

          for candidate in "${CANDIDATES[@]}"; do
            echo "üìã Trying Docker image: binbash/leverage-toolbox:$candidate"

            # Try pulling with 2 attempts per candidate
            for attempt in {1..2}; do
              if docker pull "binbash/leverage-toolbox:$candidate"; then
                echo "‚úÖ Successfully pulled: binbash/leverage-toolbox:$candidate (attempt $attempt)"
                SUCCESSFUL_IMAGE="$candidate"
                break 2  # Break out of both loops
              else
                echo "‚ö†Ô∏è Failed to pull $candidate on attempt $attempt"
                sleep 3
              fi
            done
          done

          if [[ -z "$SUCCESSFUL_IMAGE" ]]; then
            echo "‚ùå Failed to pull any Docker images from candidates: ${CANDIDATES[*]}"
            echo "üö® This may be a Docker Hub connectivity issue"
            exit 1
          fi

          # Update TERRAFORM_IMAGE_TAG to the successful image
          echo "TERRAFORM_IMAGE_TAG=$SUCCESSFUL_IMAGE" >> $GITHUB_ENV
          echo "‚úÖ Using Docker image: binbash/leverage-toolbox:$SUCCESSFUL_IMAGE"

          # Verify image exists locally
          if docker images "binbash/leverage-toolbox:$TERRAFORM_IMAGE_TAG" --format "table {{.Repository}}:{{.Tag}}" | grep -q "$TERRAFORM_IMAGE_TAG"; then
            echo "‚úÖ Docker image verified locally"
          else
            echo "‚ùå Docker image not found locally after pull"
            exit 1
          fi

      - name: Run Leverage CLI validations
        id: validation
        working-directory: ${{ matrix.layer }}
        run: |
          echo "üöÄ Running validations in $(pwd)"

          # Initialize validation results
          VALIDATION_RESULTS=""
          VALIDATION_STATUS="success"

          # Function to capture command output
          run_validation() {
            local cmd="$1"
            local description="$2"

            echo "‚ö° Running: $description"
            if output=$(timeout 300 $cmd 2>&1); then
              echo "‚úÖ $description: PASSED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n‚úÖ **PASSED**\n\`\`\`\n${output}\n\`\`\`\n\n"
            else
              echo "‚ùå $description: FAILED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n‚ùå **FAILED**\n\`\`\`\n${output}\n\`\`\`\n\n"
              VALIDATION_STATUS="failed"
            fi
          }

          # Run validation commands using detected binary and configured environment
          echo "üîß Using Terraform binary: ${{ steps.tf-compat.outputs.tf-binary }}"
          echo "üê≥ Using Docker image: binbash/leverage-toolbox:$TERRAFORM_IMAGE_TAG"
          echo "üìÅ Working directory: $(pwd)"
          echo "üîç Repository root: $(git rev-parse --show-toplevel)"
          echo "üîë AWS Profile: ${{ steps.aws-profiles.outputs.aws-profile }}"
          echo "üåç AWS Region: $AWS_DEFAULT_REGION"

          # Let Leverage CLI handle binary detection natively
          echo "üîç Trusting Leverage CLI to handle OpenTofu/Terraform binary detection"
          echo "‚úÖ Using detected command: ${{ steps.tf-compat.outputs.tf-command }}"

          # Verify AWS configuration
          echo "üîç AWS Configuration verification:"
          aws configure list || echo "AWS CLI not configured"
          aws sts get-caller-identity || echo "AWS credentials test failed"

          # Debug leverage environment
          echo "üê≥ Docker and Leverage environment debugging:"
          echo "Current working directory: $(pwd)"
          echo "Files in directory: $(ls -la)"
          echo "Build.env file:"
          cat build.env || echo "No build.env found"
          echo "Docker images:"
          docker images | grep leverage || echo "No leverage images found"
          echo "Leverage CLI test:"
          leverage --version || echo "Leverage CLI not accessible"

          # Enhanced validation with fallback
          run_validation_with_fallback() {
            local cmd="$1"
            local description="$2"
            local fallback_cmd="$3"

            echo "‚ö° Running: $description"
            if output=$(timeout 300 $cmd 2>&1); then
              echo "‚úÖ $description: PASSED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n‚úÖ **PASSED**\n\`\`\`\n${output}\n\`\`\`\n\n"
            elif [[ -n "$fallback_cmd" ]]; then
              echo "‚ö†Ô∏è Primary command failed, trying fallback: $fallback_cmd"
              if fallback_output=$(timeout 300 $fallback_cmd 2>&1); then
                echo "‚úÖ $description (fallback): PASSED"
                VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description (fallback)\n‚úÖ **PASSED**\n\`\`\`\n${fallback_output}\n\`\`\`\n\n"
              else
                echo "‚ùå $description: FAILED (both primary and fallback)"
                VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n‚ùå **FAILED**\n\`\`\`\nPrimary: ${output}\n\nFallback: ${fallback_output}\n\`\`\`\n\n"
                VALIDATION_STATUS="failed"
              fi
            else
              echo "‚ùå $description: FAILED"
              VALIDATION_RESULTS="${VALIDATION_RESULTS}## $description\n‚ùå **FAILED**\n\`\`\`\n${output}\n\`\`\`\n\n"
              VALIDATION_STATUS="failed"
            fi
          }

          run_validation_with_fallback "leverage $TF_COMMAND fmt -check" "Terraform Format Check" "terraform fmt -check"
          run_validation_with_fallback "leverage $TF_COMMAND init -no-color" "Terraform Initialization" "terraform init -no-color"
          run_validation "leverage $TF_COMMAND validate" "Terraform Validation"

          # Generate execution plan (non-blocking)
          echo "üìã Generating execution plan with ${{ steps.tf-compat.outputs.tf-binary }}..."
          if plan_output=$(timeout 600 leverage $TF_COMMAND plan -no-color 2>&1); then
            echo "‚úÖ Plan generation: PASSED"
            VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Plan\n‚úÖ **GENERATED**\n\`\`\`\n${plan_output}\n\`\`\`\n\n"
          else
            echo "‚ö†Ô∏è Plan generation: WARNING"
            VALIDATION_RESULTS="${VALIDATION_RESULTS}## Terraform Plan\n‚ö†Ô∏è **WARNING**\n\`\`\`\n${plan_output}\n\`\`\`\n\n"
          fi

          # Save results to file for next job
          mkdir -p /tmp/validation-results
          LAYER_FILE_NAME="${{ matrix.layer }}"
          LAYER_FILE_NAME="${LAYER_FILE_NAME//\//-}"  # Replace slashes with dashes
          echo -e "$VALIDATION_RESULTS" > "/tmp/validation-results/${LAYER_FILE_NAME}.md"
          echo "$VALIDATION_STATUS" > "/tmp/validation-results/${LAYER_FILE_NAME}.status"

          echo "status=$VALIDATION_STATUS" >> $GITHUB_OUTPUT

          # Create layer slug for unique artifact naming
          LAYER_SLUG="${{ matrix.layer }}"
          LAYER_SLUG="${LAYER_SLUG//\//-}"  # Replace slashes with dashes
          echo "layer-slug=$LAYER_SLUG" >> $GITHUB_OUTPUT

      - name: Upload validation results
        uses: actions/upload-artifact@v4
        with:
          name: validation-results-${{ steps.validation.outputs.layer-slug }}
          path: /tmp/validation-results/
          retention-days: 1

  # Job 3: AI-powered analysis of validation results
  ai-analysis:
    name: AI Analysis
    needs: [detect-layers, validate-layers]
    if: needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download validation results
        uses: actions/download-artifact@v4
        with:
          pattern: validation-results-*
          path: /tmp/validation-results/
          merge-multiple: true

      - name: Load AI personas configuration
        id: load-personas
        run: |
          # Load AI personas from configuration file
          if [[ -f .github/ai-personas.yml ]]; then
            echo "üìö Loading AI personas configuration"
            cat .github/ai-personas.yml
          else
            echo "‚ö†Ô∏è AI personas configuration not found, using defaults"
          fi

      - name: Analyze validation results with AI
        id: ai-analysis
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ü§ñ Starting AI analysis of validation results"

          # Get PR diff for context
          PR_DIFF=$(gh api repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/files \
            --jq '.[] | "File: \(.filename)\nStatus: \(.status)\nChanges: +\(.additions) -\(.deletions)\n---"' | head -c 8000)

          # Collect all validation results
          COMBINED_RESULTS="# Validation Results Summary\n\n"
          OVERALL_STATUS="success"

          for result_file in /tmp/validation-results/*.md; do
            if [[ -f "$result_file" ]]; then
              layer_path=$(basename "$result_file" .md)
              status=$(cat "/tmp/validation-results/${layer_path}.status" 2>/dev/null || echo "unknown")

              if [[ "$status" == "failed" ]]; then
                OVERALL_STATUS="failed"
              fi

              COMBINED_RESULTS="${COMBINED_RESULTS}## Layer: $layer_path (Status: $status)\n"
              COMBINED_RESULTS="${COMBINED_RESULTS}$(cat "$result_file")\n"
            fi
          done

          # Prepare AI prompt (simple format to avoid YAML issues)
          AI_PROMPT_BASE="You are an expert DevOps engineer analyzing Terraform infrastructure changes in a Binbash Leverage Reference Architecture project. Context: Repository ${{ github.repository }}, PR #${{ github.event.pull_request.number }}: ${{ github.event.pull_request.title }}. Architecture: Multi-account AWS with layer-based structure. Please provide: 1. Executive Summary, 2. Key Findings, 3. Potential Issues, 4. Recommendations, 5. Cross-Layer Impact Analysis, 6. Risk Assessment. Focus on infrastructure best practices, security implications, and cross-layer dependencies."

          # Combine prompt with data (truncate if too long)
          FULL_PROMPT="${AI_PROMPT_BASE} PR Changes: $(echo "$PR_DIFF" | head -c 3000) Validation Results: $(echo "$COMBINED_RESULTS" | head -c 3000)"

          # Call GitHub Models API
          echo "üß† Calling GitHub Models API for analysis..."

          # Create JSON payload and call API
          JSON_PAYLOAD=$(jq -n --arg model "openai/gpt-4.1" --arg content "$FULL_PROMPT" '{"model": $model, "messages": [{"role": "user", "content": $content}], "temperature": 0.3, "max_tokens": 2000}')

          # Make API call with error handling
          echo "Calling GitHub Models API..."
          API_RESPONSE=$(curl -s -w "HTTP_CODE:%{http_code}" -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            -H "Content-Type: application/json" \
            -d "$JSON_PAYLOAD" \
            "https://models.github.ai/inference/chat/completions")

          # Extract HTTP code and response body
          HTTP_CODE=$(echo "$API_RESPONSE" | grep -o 'HTTP_CODE:[0-9]*' | cut -d: -f2)
          RESPONSE_BODY=$(echo "$API_RESPONSE" | sed 's/HTTP_CODE:[0-9]*$//')

          # Process API response
          if [[ "$HTTP_CODE" == "200" ]]; then
            AI_CONTENT=$(echo "$RESPONSE_BODY" | jq -r '.choices[0].message.content // "AI analysis parsing failed"')
            echo "‚úÖ AI analysis successful"
          else
            echo "‚ö†Ô∏è AI analysis failed with HTTP code $HTTP_CODE"
            echo "üìã API Response Body: $RESPONSE_BODY"
            echo "üìä Payload Size: $(echo "$JSON_PAYLOAD" | wc -c) characters"

            # Try to extract error message from response
            ERROR_MSG=$(echo "$RESPONSE_BODY" | jq -r '.error.message // .message // "Unknown error"' 2>/dev/null || echo "Unable to parse error")
            AI_CONTENT="AI analysis temporarily unavailable (HTTP $HTTP_CODE: $ERROR_MSG). Validation results are still available above."
          fi

          # Save AI response
          mkdir -p /tmp/ai-analysis
          echo "$AI_CONTENT" > /tmp/ai-analysis/response.md
          echo "$OVERALL_STATUS" > /tmp/ai-analysis/status.txt

          echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT

      - name: Upload AI analysis
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis
          path: /tmp/ai-analysis/
          retention-days: 1

  # Job 4: Post results as PR comments
  post-results:
    name: Post AI Analysis Results
    needs: [detect-layers, validate-layers, ai-analysis]
    if: always() && needs.detect-layers.outputs.has-changes == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Download AI analysis
        uses: actions/download-artifact@v4
        with:
          name: ai-analysis
          path: /tmp/ai-analysis/

      - name: Post AI analysis as PR comment
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üí¨ Posting AI analysis to PR #${{ github.event.pull_request.number }}"

          # Load AI response
          if [[ -f /tmp/ai-analysis/response.md ]]; then
            AI_RESPONSE=$(cat /tmp/ai-analysis/response.md)
            OVERALL_STATUS=$(cat /tmp/ai-analysis/status.txt)
          else
            AI_RESPONSE="AI analysis was not available for this validation run."
            OVERALL_STATUS="unknown"
          fi

          # Determine status emoji
          case "$OVERALL_STATUS" in
            "success") STATUS_EMOJI="‚úÖ" ;;
            "failed") STATUS_EMOJI="‚ùå" ;;
            *) STATUS_EMOJI="‚ö†Ô∏è" ;;
          esac

          # Create simple PR comment (building it step by step to avoid YAML issues)
          PR_COMMENT="${STATUS_EMOJI} AI-Powered Infrastructure Validation"
          PR_COMMENT+="\n\n**Overall Status:** \`$OVERALL_STATUS\`"
          PR_COMMENT+="\n\n$AI_RESPONSE"
          PR_COMMENT+="\n\n---"
          PR_COMMENT+="\n**Interactive Commands:** Reply with @aibot commands for additional analysis:"
          PR_COMMENT+="\n- \`@aibot explain security risks\`"
          PR_COMMENT+="\n- \`@aibot blast radius\`"
          PR_COMMENT+="\n- \`@aibot best practices\`"
          PR_COMMENT+="\n\n*Powered by Binbash Leverage + GitHub Models API*"

          # Post comment
          gh api repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/comments \
            --method POST \
            --field body="$PR_COMMENT"

          echo "‚úÖ AI analysis posted successfully"

  # Job 5: Handle @aibot interactive commands (triggered by issue comments)
  handle-aibot:
    name: Handle @aibot Commands
    runs-on: ubuntu-latest
    if: github.event_name == 'issue_comment' && contains(github.event.comment.body, '@aibot')
    steps:
      - name: Process @aibot command
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          COMMENT_BODY="${{ github.event.comment.body }}"
          echo "ü§ñ Processing @aibot command: $COMMENT_BODY"

          # Extract command after @aibot
          COMMAND=$(echo "$COMMENT_BODY" | sed -n 's/.*@aibot \([^[:space:]]*\).*/\1/p')

          case "$COMMAND" in
            "explain"|"security"|"blast"|"best")
              # Create prompt based on command
              case "$COMMAND" in
                "explain"|"security")
                  BOT_PROMPT="You are a security expert. Analyze the infrastructure changes in this PR and explain potential security risks, vulnerabilities, and recommended mitigations. Focus on AWS security best practices."
                  ;;
                "cost")
                  BOT_PROMPT="You are a cost optimization expert. Analyze the infrastructure changes and estimate cost impact, potential savings opportunities, and cost-effective alternatives."
                  ;;
                "blast")
                  BOT_PROMPT="You are an infrastructure expert. Analyze cross-layer dependencies and predict the blast radius of these changes on other infrastructure components."
                  ;;
                "best")
                  BOT_PROMPT="You are an AWS Well-Architected Framework expert. Review these changes against the 5 pillars: Security, Reliability, Performance, Cost Optimization, and Operational Excellence."
                  ;;
              esac

              # Create JSON payload for API call
              JSON_PAYLOAD=$(jq -n \
                --arg model "openai/gpt-4.1" \
                --arg content "$BOT_PROMPT" \
                '{
                  "model": $model,
                  "messages": [
                    {
                      "role": "user",
                      "content": $content
                    }
                  ],
                  "temperature": 0.3,
                  "max_tokens": 1500
                }')

              # Call GitHub Models API
              AI_RESPONSE=$(curl -s -X POST \
                -H "Accept: application/vnd.github+json" \
                -H "Authorization: Bearer $GITHUB_TOKEN" \
                -H "X-GitHub-Api-Version: 2022-11-28" \
                -H "Content-Type: application/json" \
                -d "$JSON_PAYLOAD" \
                "https://models.github.ai/inference/chat/completions" | \
                jq -r '.choices[0].message.content // "Analysis unavailable"')

              # Reply to comment
              AIBOT_RESPONSE="ü§ñ **@aibot response for \`$COMMAND\`:**\n\n$AI_RESPONSE"
              gh api repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments \
                --method POST \
                --field body="$AIBOT_RESPONSE"
              ;;
            *)
              AIBOT_HELP="ü§ñ Available @aibot commands:\n- \`@aibot explain security risks\`\n- \`@aibot blast radius\`\n- \`@aibot best practices\`"
              gh api repos/${{ github.repository }}/issues/${{ github.event.issue.number }}/comments \
                --method POST \
                --field body="$AIBOT_HELP"
              ;;
          esac